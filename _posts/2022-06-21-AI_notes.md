---
layout: post
title:  AI_CLassNotes_Week2
date: 2022-06-21 21:01:00
description: This are Class Notes From AI504 Class
tags: KAIST ClassNotes
categories: [AI, Class]
---

Disclaimer:
This Page is a classNote from the Class AI504 week 2 taught by prof. Edwardchoi at KAIST
<br>
<br>


# Week2: Basic Machine Learning

# What is machine learning?

## AI

AI: artificial intelligence is everything in a machine/computers that mimic human intelligence (does not necessarily needs the “Deep learning” component)
**ex) chess playing program**

## Machine Learning

ML: Statistical method to teach machine to learn from data and execute specific task
**Ex) Spam Filtering**

## Deep Learning

DL: Subdomain of Machine Learning, Applies neural network and massive data to execute machine learning
Ex) ALpha Go

{% include figure.html path="assets/markdown_assets/AI_notes/screenshot.png" title="AI_ML_DL" class="img-fluid rounded z-depth-1" %}

# Why Deep Learning?

- We need less feature engineering
- You dont need to define what feature are doglike or catlike

# Machine Learning Categories

## Supervised Learning

Learn a function that maps an input (x) to an output (y)

Ex) Image classification, translation, Image captioning

![Untitled](Week2%20Basic%20Machine%20Learning%2044acc6d60715436682aca4cf973e089c/Untitled.png)

## Unsupervised Learning

Learn a distribution/manifold function of data (x). Theres no label **y**

Ex) Clustering, Topic Model, Low-rank matrix factorization, Generative models

## Reinforcement Learning

There is an environment (E) and a set of action (A), learn a function that maximizes the long-term rewards (R)

Ex) alpha-Go, any game

The lines between Supervised Learning and Unsupervised Learning are a bit blurry. (Generative models and self-supervised learning)

# Optimization

In all of the three categories (SL, UL, RL) you need to train your model (a.k.a learn a function)

## How to train a model $f(x; \theta)$

1. You need a goal (objective)
2. We need a function to achieve goal (objective function)
3. Define the loss function
$loss (y,y')$
4. Find the $\theta$  that minimizes (optimize)
$loss(y, f(x;\theta))$

![Untitled](Week2%20Basic%20Machine%20Learning%2044acc6d60715436682aca4cf973e089c/Untitled%201.png)

### Gradient Descent

- Gradient Descent does not guarantee that you are in the global minimum
    - You need to iterate over a number of epochs to increase the chances of achieving a global minimum

![Untitled](Week2%20Basic%20Machine%20Learning%2044acc6d60715436682aca4cf973e089c/Untitled%202.png)

### Stochastic Gradient Descent

![Untitled](Week2%20Basic%20Machine%20Learning%2044acc6d60715436682aca4cf973e089c/Untitled%203.png)

### How do you know when to stop SGD?

- Using the value of a loss function is not very intuitive
    - what does $10^{-3}$ or $10^{-4}$ means?
- For that we have popular evaluation metrics
    - Accuracy (Muti classification)
    - AUROC (Binary Classification)
    - Precision & Recall
    - BLEU Score (Machine Translation)
    - Perplexity (Language modeling or Text generation)
    - FID Score (Image data)

# Train & Validation & Test

- Training Set
    - Used to train the model

- Validation Set
    - Used this to evaluate model

- Test Set
    - Needs to remain unseen
    - Cannot use this set during training set

## N-fold Cross Validation

- Testing the model’s performance in diverse train/validation/test splits
    - In the example below we divide the data into 8 subsets and rotate the training-validation data and test data in each iteration to verify that the results were not out of luck.
- Not often used in modern deep learning

![Untitled](Week2%20Basic%20Machine%20Learning%2044acc6d60715436682aca4cf973e089c/Untitled%204.png)

## Overfitting & Underfitting

- Basically you have to leverage between data complexity vs model capacity
    
    ![Untitled](Week2%20Basic%20Machine%20Learning%2044acc6d60715436682aca4cf973e089c/Untitled%205.png)
    
- Doing to well on training data does **not always transmit to good  test performance**

## The Curse of Dimensionality

- When a model is **underfitting** you can add
    - More features to find a better fit.
        - Altough you increase linear in the number of the feature.
            - That increases exponentially the number of data
                
                ![Untitled](Week2%20Basic%20Machine%20Learning%2044acc6d60715436682aca4cf973e089c/Untitled%206.png)
                
    - Add complexity to the model
    - Train longer
- When a model is over fitting you can
    - Restrict the freedom of your model
    - Downsize the hypothesis space
        
        ![Untitled](Week2%20Basic%20Machine%20Learning%2044acc6d60715436682aca4cf973e089c/Untitled%207.png)
        
    - You can use L1, L2, etc.. (anything that restrict the freedom)

# Popular Classifier of ML

## Logstic Regression

- Probability → Odds → Log of Odds (Logit)

![Untitled](Week2%20Basic%20Machine%20Learning%2044acc6d60715436682aca4cf973e089c/Untitled%208.png)

## Support Vector Machine

- Very famous before Deep Learning
- Maximize the margin between two cases
- Trained via constrained optimization (KKT condition)
    - Today you use gradient descent with hinge loss

![Untitled](Week2%20Basic%20Machine%20Learning%2044acc6d60715436682aca4cf973e089c/Untitled%209.png)

## Decision Tree

- Build a tree based on features
- Trained via the CART algorithm

![Untitled](Week2%20Basic%20Machine%20Learning%2044acc6d60715436682aca4cf973e089c/Untitled%2010.png)

## Ensembles

- Use multiple classifiers to improve performance

- ***Bagging***
    - Train multiple classifiers on different subset of data
    - Train multiple classifiers on different subset of features

![Untitled](Week2%20Basic%20Machine%20Learning%2044acc6d60715436682aca4cf973e089c/Untitled%2011.png)

- ***Boosting***
    - (K+1)th classifier tries to correct the k-th classifiers errors.
    - A kind of a chain of classifiers

![Untitled](Week2%20Basic%20Machine%20Learning%2044acc6d60715436682aca4cf973e089c/Untitled%2012.png)

# Popular Clustering

## K-means

- Updates membership of each sample using the closest centroid
- Update the centroid value using all the member samples
- Repeat

![Untitled](Week2%20Basic%20Machine%20Learning%2044acc6d60715436682aca4cf973e089c/Untitled%2013.png)

# Resource

[Programming for AI (AI504, Fall 2020), Class 2: Basic Machine Learning](https://www.youtube.com/watch?v=WMtgssrJteA)

[Programming for AI (AI504, Fall 2020), Practice 2: Basic Machine Learning](https://www.youtube.com/watch?v=Rt3TgEemVYI)